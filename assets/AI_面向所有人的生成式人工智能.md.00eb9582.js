import{_ as l,o as i,c as e,a as r}from"./app.20213b8a.js";const g=JSON.parse('{"title":"生成式人工智能-Coursera","description":"","frontmatter":{"tags":["AI"],"date":"2024-01-14-周日","cdate":"2024-01-14T16:52:40.000Z","mdate":"2024-01-31T16:52:40.000Z","status":"done","title":"生成式人工智能-Coursera","hours":"11.5"},"headers":[{"level":2,"title":"前言","slug":"前言","link":"#前言","children":[]},{"level":2,"title":"术语概念","slug":"术语概念","link":"#术语概念","children":[]},{"level":2,"title":"问答","slug":"问答","link":"#问答","children":[]}],"relativePath":"AI/面向所有人的生成式人工智能.md","lastUpdated":1715164291000}'),a={name:"AI/面向所有人的生成式人工智能.md"},t=r('<h1 id="生成式人工智能-coursera" tabindex="-1">生成式人工智能 -Coursera <a class="header-anchor" href="#生成式人工智能-coursera" aria-hidden="true">#</a></h1><h2 id="前言" tabindex="-1">前言 <a class="header-anchor" href="#前言" aria-hidden="true">#</a></h2><ul><li><a href="https://www.coursera.org/learn/generative-ai-for-everyone?isNewUser=true" target="_blank" rel="noreferrer">面向所有人的生成式人工智能-coursera课程</a></li></ul><h2 id="术语概念" tabindex="-1">术语概念 <a class="header-anchor" href="#术语概念" aria-hidden="true">#</a></h2><ul><li>Large-scale supervised learning（大规模监督学习）：一种输入 A 输出 B ，预测下一个词的技术。</li><li>Large language model(LLM)：是使用监督学习来构建的。从大量数据中汲取，可以预测下一个单词是什么。</li><li>hallucination（幻觉）： LLM 编造事实。</li></ul><h2 id="问答" tabindex="-1">问答 <a class="header-anchor" href="#问答" aria-hidden="true">#</a></h2><ul><li>LLM 可以干什么？<br> 给定提示词，输出后续内容，比如编故事。</li><li>什么时候用 web 搜索，什么时候用 LLM ？<br> 需要权威答案的时候用 web 搜索，因为 LLM 可能瞎编。创造性的可以让 LLM 来。</li><li>生成式 AI 有什么用？<br> 人工智能是一种通用技术，就像电一样，各行各业，方方面面，无处不在。</li><li>生成式 AI 具体用处举例？<br> 将 LLM 构建到更大的软件自动化中，比如 1 识别邮件内容是否为投诉邮件，构建我们的邮件处理任务。2 机器人聊天。</li><li>大语言模型可以做什么？不可以做什么？ <ul><li>训练材料是有时间限制的，对于未发生的事可能因为幻觉输出与事实相反的信息。</li><li>输入输出信息长度有限制，比如总结很长的论文可能需要先把论文拆成几个部分，或找找具有更长输入限制的大语言模型。</li><li><strong>不能很好的理解结构化数据，比如存储在表格中的数据。非结构化数据是指文本、图像、音频、视频</strong>。</li></ul></li><li>一些大语言模型提示技巧 <ul><li>清晰而具体</li><li>引导模型去思考答案</li><li>重新定义提示，重复这个步骤，这是个高度迭代的过程</li></ul></li><li>图像生成<br> 主要是靠一些扩散模型（diffusion model），扩撒模型的核心是监督学习，具体就是先生成噪点图片再逐步到清晰具体的图片的过程。</li><li>生成式 AI 项目的生命周期 <ul><li>确定项目使用范围</li><li>创建改善系统</li><li>内部评估</li><li>全球范围内部署和监督，发现错误后迭代这个过程</li></ul></li><li>成本直觉<br> 博士通过计算每小时处理数据的成本，人工和 LLM 对比，LLM 更便宜。人工每小时阅读按大概 250✖️60 个字算，LLM 处理同样的工作量一小时只需要 8 美分，远远比人工便宜。</li><li>RAG 如何工作的？（RAG：retrieveal augmented generation 检索增强生成技术，一种可以向 LLM 提供额外信息的技术） <ul><li>给出一个问题，它将浏览一系列可能的文档，找最相关的文本</li><li>合并检索到的文本更新到提示中</li><li>通过上下文和新的提示，生成新的答案（还会生成指向源文档的链接，用户可以根据阅读源文档，亲自检验答案）<br> 博士建议<strong>不要将 LLM 当做知识库信息来源，应该当做推理引擎</strong>，LLM 虽然知道很多事，但并不是什么都知道。</li></ul></li><li>为什么使用微调技术（一种可以向 LLM 提供额外信息的技术） <ul><li>执行那些在提示中不容易定义的任务</li><li>使用较小的模型来执行以前那些可能需要更大模型的任务（小模型相对于大模型在算力方面更便宜更快速）</li></ul></li><li>预训练：大量数据上训练 LLM 的过程通常称为预训练，这种方法在当今花费的时间和费用非常昂贵，基本只有大公司在使用</li><li>RLHF(Reinforcement learning from human feedback 人工反馈进行强化学习)</li><li>如何选择模型？<br> 看了博士的分析我更倾向于<strong>开源模型放在本地部署</strong>，保留数据隐私和数据访问的完全控制</li><li>什么样的工作适合 AI？ <ul><li>AI 是自动化任务而不是自动化工作，大多数工作包含很多任务，可以使用人工智能帮助人类完成任务</li><li>评估自动化不同任务的技术可行性</li><li>商业价值，比如能节省多少时间或者 AI 是否能更快更便宜更持续的完成任务</li></ul></li><li>受 AI 影响的人 <ul><li>高薪工作者比低薪工作者更容易受影响</li></ul></li><li>生成式 AI 项目的团队角色（假设两人团队） <ul><li>软件工程师 ：负责编写软件确保正确运行</li><li>机器学习工程师：负责实施系统，学习下 LLM 基础，和一些高级技术（RAG，微调）</li></ul></li></ul>',7),n=[t];function s(o,u,d,_,c,h){return i(),e("div",null,n)}const f=l(a,[["render",s]]);export{g as __pageData,f as default};
