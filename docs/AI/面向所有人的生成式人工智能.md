---
tags:
  - AI
date: 2024-01-14-周日
cdate: 2024-01-14 16:52:40
mdate: 2024-01-31 16:52:40
status: done
title: 生成式人工智能-Coursera
hours: "11.5"
---
# 生成式人工智能 -Coursera

## 前言

- [面向所有人的生成式人工智能-coursera课程](https://www.coursera.org/learn/generative-ai-for-everyone?isNewUser=true )

## 术语概念

- Large-scale supervised learning（大规模监督学习）：一种输入 A 输出 B ，预测下一个词的技术。
- Large language model(LLM)：是使用监督学习来构建的。从大量数据中汲取，可以预测下一个单词是什么。
- hallucination（幻觉）： LLM 编造事实。

## 问答

- LLM 可以干什么？  
    给定提示词，输出后续内容，比如编故事。
- 什么时候用 web 搜索，什么时候用 LLM ？  
	需要权威答案的时候用 web 搜索，因为 LLM 可能瞎编。创造性的可以让 LLM 来。
- 生成式 AI 有什么用？  
	人工智能是一种通用技术，就像电一样，各行各业，方方面面，无处不在。
- 生成式 AI 具体用处举例？  
	将 LLM 构建到更大的软件自动化中，比如 1 识别邮件内容是否为投诉邮件，构建我们的邮件处理任务。2 机器人聊天。
- 大语言模型可以做什么？不可以做什么？   
	- 训练材料是有时间限制的，对于未发生的事可能因为幻觉输出与事实相反的信息。  
	- 输入输出信息长度有限制，比如总结很长的论文可能需要先把论文拆成几个部分，或找找具有更长输入限制的大语言模型。  
	- **不能很好的理解结构化数据，比如存储在表格中的数据。非结构化数据是指文本、图像、音频、视频**。  
- 一些大语言模型提示技巧  
    - 清晰而具体
    - 引导模型去思考答案
    - 重新定义提示，重复这个步骤，这是个高度迭代的过程
- 图像生成  
	主要是靠一些扩散模型（diffusion model），扩撒模型的核心是监督学习，具体就是先生成噪点图片再逐步到清晰具体的图片的过程。
- 生成式 AI 项目的生命周期
	- 确定项目使用范围
	- 创建改善系统
	- 内部评估
	- 全球范围内部署和监督，发现错误后迭代这个过程
- 成本直觉  
	博士通过计算每小时处理数据的成本，人工和 LLM 对比，LLM 更便宜。人工每小时阅读按大概 250✖️60 个字算，LLM 处理同样的工作量一小时只需要 8 美分，远远比人工便宜。
- RAG 如何工作的？（RAG：retrieveal augmented generation 检索增强生成技术，一种可以向 LLM 提供额外信息的技术）
	- 给出一个问题，它将浏览一系列可能的文档，找最相关的文本
	- 合并检索到的文本更新到提示中
	- 通过上下文和新的提示，生成新的答案（还会生成指向源文档的链接，用户可以根据阅读源文档，亲自检验答案）  
	博士建议**不要将 LLM 当做知识库信息来源，应该当做推理引擎**，LLM 虽然知道很多事，但并不是什么都知道。
- 为什么使用微调技术（一种可以向 LLM 提供额外信息的技术）  
	- 执行那些在提示中不容易定义的任务
	- 使用较小的模型来执行以前那些可能需要更大模型的任务（小模型相对于大模型在算力方面更便宜更快速）
- 预训练：大量数据上训练 LLM 的过程通常称为预训练，这种方法在当今花费的时间和费用非常昂贵，基本只有大公司在使用
- RLHF(Reinforcement learning from human feedback 人工反馈进行强化学习)
- 如何选择模型？  
	看了博士的分析我更倾向于**开源模型放在本地部署**，保留数据隐私和数据访问的完全控制
- 什么样的工作适合 AI？  
	- AI 是自动化任务而不是自动化工作，大多数工作包含很多任务，可以使用人工智能帮助人类完成任务
	- 评估自动化不同任务的技术可行性
	- 商业价值，比如能节省多少时间或者 AI 是否能更快更便宜更持续的完成任务
- 受 AI 影响的人
	- 高薪工作者比低薪工作者更容易受影响
- 生成式 AI 项目的团队角色（假设两人团队）
	- 软件工程师 ：负责编写软件确保正确运行
	- 机器学习工程师：负责实施系统，学习下 LLM 基础，和一些高级技术（RAG，微调）

